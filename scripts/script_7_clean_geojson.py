#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
SCRIPT 7 ‚Äî Nettoyage g√©om√©trique et pr√©paration finale
------------------------------------------------------
Entr√©e  : data_raw/parcelles.geojson
Sorties :
 - data_clean/parcelles_clean.geojson
 - outputs/geojson_clean_log.csv
 - logs/script_7_clean_geojson.log
"""

import os
import logging
import geopandas as gpd
import pandas as pd
from shapely.geometry import Polygon, MultiPolygon
from shapely.errors import TopologicalError

# ---------------- CONFIGURATION ----------------

INPUT = "data_raw/parcelles.geojson"
OUTPUT_GEOJSON = "data_clean/parcelles_clean.geojson"
SCRIPT_ID = "script_7"
LOG_DIR = f"logs/{SCRIPT_ID}"
OUT_DIR = f"outputs/{SCRIPT_ID}"
OUTPUT_LOG = f"{OUT_DIR}/geojson_clean_log.csv"

os.makedirs(LOG_DIR, exist_ok=True)
os.makedirs("data_clean", exist_ok=True)
os.makedirs(OUT_DIR, exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s",
    handlers=[
        logging.FileHandler(f"{LOG_DIR}/script_7_clean_geojson.log", encoding="utf-8"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("clean_geojson")

# ---------------- LECTURE ----------------

logger.info(f"Lecture du GeoJSON brut : {INPUT}")
gdf = gpd.read_file(INPUT)
logger.info(f"{len(gdf)} entit√©s charg√©es.")

# ---------------- CRS ----------------

if gdf.crs is None:
    logger.warning("‚ö†Ô∏è Aucun CRS d√©tect√© ‚Äî affectation forc√©e EPSG:4326.")
    gdf.set_crs(epsg=4326, inplace=True)
elif gdf.crs.to_string() != "EPSG:4326":
    logger.info(f"‚ôªÔ∏è Reprojection ‚Üí EPSG:4326 (ancien : {gdf.crs})")
    gdf = gdf.to_crs(epsg=4326)

# ---------------- JOURNAL DES CORRECTIONS ----------------

logs = []

def log_change(identifiant, action, details):
    logs.append({"identifiant": identifiant, "action": action, "details": details})

# ---------------- 1. Suppression g√©om√©tries vides ----------------

n_empty = gdf.geometry.is_empty.sum()
if n_empty > 0:
    logger.warning(f"üóëÔ∏è {n_empty} g√©om√©tries vides supprim√©es.")
    for idx in gdf[gdf.geometry.is_empty].index:
        fid = gdf.loc[idx, "Farms_ID"] if "Farms_ID" in gdf.columns else idx
        log_change(fid, "suppression", "g√©om√©trie vide")
    gdf = gdf[~gdf.geometry.is_empty]

# ---------------- 2. Correction g√©om√©tries invalides ----------------

n_invalid = (~gdf.is_valid).sum()
if n_invalid > 0:
    logger.warning(f"üõ†Ô∏è {n_invalid} g√©om√©tries invalides d√©tect√©es ‚Äî tentative de correction buffer(0).")
    for idx in gdf[~gdf.is_valid].index:
        fid = gdf.loc[idx, "Farms_ID"] if "Farms_ID" in gdf.columns else idx
        try:
            gdf.at[idx, "geometry"] = gdf.at[idx, "geometry"].buffer(0)
            log_change(fid, "correction", "geometry invalid ‚Üí valid√© buffer(0)")
        except TopologicalError:
            log_change(fid, "suppression", "geometry irr√©parable")
            gdf.drop(idx, inplace=True)
else:
    logger.info("‚úÖ Aucune g√©om√©trie invalide.")

# ---------------- 3. Suppression doublons attributaires ----------------

if "Farms_ID" in gdf.columns:
    dupli_attr = gdf[gdf.duplicated(subset=["Farms_ID"], keep=False)]
    n_dupli_attr = len(dupli_attr)
    if n_dupli_attr > 0:
        logger.warning(f"üóëÔ∏è {n_dupli_attr} doublons d'attribut supprim√©s (1 seul exemplaire conserv√©).")
        for fid in dupli_attr["Farms_ID"].unique():
            log_change(fid, "doublon_attribut", "Farms_ID dupliqu√©")
        gdf = gdf.drop_duplicates(subset=["Farms_ID"], keep="first")
else:
    logger.warning("‚ö†Ô∏è Colonne Farms_ID absente ‚Äî pas de d√©duplication possible.")

# ---------------- 4. Suppression doublons g√©om√©triques ----------------

logger.info("üîç D√©tection des doublons g√©om√©triques exacts...")
geom_hash = gdf.geometry.apply(lambda g: None if g is None else g.wkb_hex)
dupli_geom_mask = geom_hash.duplicated(keep=False)

n_dupli_geom = dupli_geom_mask.sum()
if n_dupli_geom > 0:
    logger.warning(f"üóëÔ∏è {n_dupli_geom} doublons g√©om√©triques d√©tect√©s.")

    # On ne garde que le premier exemplaire de chaque g√©om√©trie unique
    gdf = gdf.loc[~geom_hash.duplicated(keep="first")].copy()

    logger.info(f"‚úÖ {n_dupli_geom} doublons g√©om√©triques supprim√©s (premier conserv√©).")

    # Journalisation (on refait le hash sur le gdf r√©duit)
    geom_hash = gdf.geometry.apply(lambda g: None if g is None else g.wkb_hex)
    geom_counts = geom_hash.value_counts()
    for h, cnt in geom_counts.items():
        if cnt > 1:
            # normalement aucun, mais garde la logique
            log_change(f"hash:{h[:16]}", "doublon_g√©om√©trique", f"{cnt} occurrences")
else:
    logger.info("‚úÖ Aucun doublon g√©om√©trique d√©tect√©.")


# ---------------- 5. Recalcul des superficies ----------------

logger.info("üìê Recalcul des superficies r√©elles (ha)...")
gdf_area = gdf.to_crs(epsg=3857)  # projection m√©trique
gdf["surface_calculee_ha"] = gdf_area.geometry.area / 10_000

logger.info("‚úÖ Superficies calcul√©es et ajout√©es sous 'surface_calculee_ha'.")

# ---------------- 6. EXPORT ----------------

logger.info(f"üíæ Export du GeoJSON nettoy√© ‚Üí {OUTPUT_GEOJSON}")
gdf.to_file(OUTPUT_GEOJSON, driver="GeoJSON", encoding="utf-8")

pd.DataFrame(logs).to_csv(OUTPUT_LOG, index=False, encoding="utf-8")
logger.info(f"üßæ Journal des corrections ‚Üí {OUTPUT_LOG}")

logger.info("‚úîÔ∏è Nettoyage g√©om√©trique termin√© avec succ√®s.")
